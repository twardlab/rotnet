{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# set path to directory of file\n",
    "path = os.getcwd()\n",
    "# move up one directory and go down into Repos, then into rotnet\n",
    "path = os.path.abspath(os.path.join(path, os.pardir, 'Repos', 'rotnet'))\n",
    "# add path to sys\n",
    "sys.path.append(path)\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "\n",
    "import importlib\n",
    "import moment_kernels as mk\n",
    "importlib.reload(mk)\n",
    "\n",
    "import torch\n",
    "import torch.nn as tnn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import e2cnn.nn as enn\n",
    "import e2cnn.gspaces as gspaces\n",
    "\n",
    "# located in /rotnet/benchmark/benchmark_models.py\n",
    "from benchmark.benchmark_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = \"dermamnist\"\n",
    "download = True\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transforms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms to convert from image to normalized tensor (or more if augmentation)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5], std = [0.5]),\n",
    "])\n",
    "\n",
    "# separate transforms for test\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5], std = [0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Splitting and Shuffling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /ifshome/jliem/.medmnist/dermamnist.npz\n",
      "Using downloaded and verified file: /ifshome/jliem/.medmnist/dermamnist.npz\n",
      "Using downloaded and verified file: /ifshome/jliem/.medmnist/dermamnist.npz\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DataClass(split = \"train\", transform = train_transforms, download = download)\n",
    "valid_dataset = DataClass(split = \"val\", transform = test_transforms, download = download)\n",
    "test_dataset = DataClass(split = \"test\", transform = test_transforms, download = download)\n",
    "\n",
    "train_loader = data.DataLoader(dataset = train_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "valid_loader = data.DataLoader(dataset = valid_dataset, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = data.DataLoader(dataset = test_dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# nn0 = VanillaCNN(img_channels = 3, n0 = 32, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "# nn1 = TrivialECNN(img_channels = 3, n0 = 32, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "# nn2 = TrivialIrrepECNN(img_channels = 3, n0 = 32, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "# nn3 = RegularECNN(img_channels = 3, n0 = 32, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "# nn4 = TrivialMoment(img_channels = 3, n0 = 32, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "# nn5 = TrivialIrrepMoment(img_channels = 3, n0 = 16, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7])\n",
      "tensor([[-0.7257,  1.4012,  0.6860,  0.3275, -1.3211, -0.3494, -0.8620]])\n"
     ]
    }
   ],
   "source": [
    "def test_model(model: torch.nn.Module):\n",
    "    model.eval()\n",
    "\n",
    "    x = torch.randn(1, 3, 28, 28).to(device)\n",
    "    with torch.no_grad():\n",
    "        y = model(x)\n",
    "        print(y.shape)\n",
    "        print(y)\n",
    "    return y\n",
    "\n",
    "# output = test_model(nn5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dermaMNIST data\n",
    "# pick our 6 models\n",
    "# optim: Adam (w/ lr 1e-4) no wd or data augmentation\n",
    "# train for 100 epochs\n",
    "# every epoch, save the AUC and accuracy on the val set\n",
    "# at end, report the AUC and accuracy for the final network\n",
    "# report AUC and accuracy for the best version of the network\n",
    "# Best accuracy version, best AUC version.\n",
    "# Each network gets 3 scores\n",
    "# Time each epoch save it\n",
    "# find an approximate n_channels for vanilla and approximate number of parameters in all other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1574151\n"
     ]
    }
   ],
   "source": [
    "nn0 = VanillaCNN(img_channels = 3, n0 = 32, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "\n",
    "# count number of parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(nn0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1554527\n"
     ]
    }
   ],
   "source": [
    "nn4 = TrivialMoment(img_channels = 3, n0 = 55, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "\n",
    "print(count_parameters(nn4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565621\n"
     ]
    }
   ],
   "source": [
    "nn5 = TrivialIrrepMoment(img_channels = 3, n0 = 59, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "\n",
    "print(count_parameters(nn5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1540404\n"
     ]
    }
   ],
   "source": [
    "nn1 = TrivialECNN(img_channels = 3, n0 = 67, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "\n",
    "print(count_parameters(nn1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562221\n"
     ]
    }
   ],
   "source": [
    "nn2 = TrivialIrrepECNN(img_channels = 3, n0 = 62, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "\n",
    "print(count_parameters(nn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500090\n"
     ]
    }
   ],
   "source": [
    "nn3 = RegularECNN(img_channels = 3, n0 = 29, n_classes = n_classes, kernel_size = 3, padding = 1, num_layers = 5).to(device)\n",
    "\n",
    "print(count_parameters(nn3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
