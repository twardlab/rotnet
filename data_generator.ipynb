{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /nafs/dtward/allen/npz_files\n",
    "# this a npz file\n",
    "# when you load it you will get a dictionary with two keys\n",
    "# I (for image)\n",
    "# this is a 3D array where the first index is cell density, and all the other indices are gene expression level\n",
    "# so it is 501 x rows x cols big\n",
    "# the other key is L (for label)\n",
    "# this is a 1 x rows x cols sized array\n",
    "# it contains an integer id describing the anatomical structure of interest\n",
    "# the file is really big and is compressed, so almost certainly you'll need to do some preprocessing to extract small ROIs and save them\n",
    "\n",
    "#preprocessing step where I choose ROI per slice and write out and save as separate files\n",
    "\n",
    "#right is 0, left is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()\n",
    "par_path = os.path.abspath(os.pardir)\n",
    "sys.path.append(par_path)\n",
    "\n",
    "from utils.data import ExtractROI, AtlasDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import math\n",
    "import random as rand\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [07:19<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All ROIs extracted from /nafs/dtward/allen/npz_files/ and saved to /nafs/dtward/allen/rois/64x64_sample_rate_0_5_mode/ under train and test subfolders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ROI_size = (64, 64)\n",
    "sampling_rate = 0.5\n",
    "str_sampling_rate = str(sampling_rate).replace('.', '_')\n",
    "\n",
    "extract_dir = '/nafs/dtward/allen/npz_files/'\n",
    "save_dir = '/nafs/dtward/allen/rois/'\n",
    "sub_save_dir = f\"{ROI_size[0]}x{ROI_size[1]}_sample_rate_{str_sampling_rate}_center/\"\n",
    "abs_save_dir = os.path.join(save_dir, sub_save_dir)\n",
    "\n",
    "extractor_center = ExtractROI(extract_dir=extract_dir, save_dir=abs_save_dir)\n",
    "extractor_center.extract_ROI(ROI_size=ROI_size, sampling_rate=sampling_rate, label_mode='center')\n",
    "\n",
    "ROI_size = (64, 64)\n",
    "sampling_rate = 0.5\n",
    "str_sampling_rate = str(sampling_rate).replace('.', '_')\n",
    "\n",
    "extract_dir = '/nafs/dtward/allen/npz_files/'\n",
    "save_dir = '/nafs/dtward/allen/rois/'\n",
    "sub_save_dir = f\"{ROI_size[0]}x{ROI_size[1]}_sample_rate_{str_sampling_rate}_all/\"\n",
    "abs_save_dir = os.path.join(save_dir, sub_save_dir)\n",
    "\n",
    "extractor_all = ExtractROI(extract_dir=extract_dir, save_dir=abs_save_dir)\n",
    "extractor_all.extract_ROI(ROI_size=ROI_size, sampling_rate=sampling_rate, label_mode='all')\n",
    "\n",
    "ROI_size = (64, 64)\n",
    "sampling_rate = 0.5\n",
    "str_sampling_rate = str(sampling_rate).replace('.', '_')\n",
    "\n",
    "extract_dir = '/nafs/dtward/allen/npz_files/'\n",
    "save_dir = '/nafs/dtward/allen/rois/'\n",
    "sub_save_dir = f\"{ROI_size[0]}x{ROI_size[1]}_sample_rate_{str_sampling_rate}_mode/\"\n",
    "abs_save_dir = os.path.join(save_dir, sub_save_dir)\n",
    "\n",
    "extractor_all = ExtractROI(extract_dir=extract_dir, save_dir=abs_save_dir)\n",
    "extractor_all.extract_ROI(ROI_size=ROI_size, sampling_rate=sampling_rate, label_mode='mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/nafs/dtward/allen/rois/64x64_sample_rate_0_5_mode/train/'\n",
    "test_dir = '/nafs/dtward/allen/rois/64x64_sample_rate_0_5_mode/test/'\n",
    "\n",
    "train_dataset = AtlasDataset(data_dir=train_dir)\n",
    "test_dataset = AtlasDataset(data_dir=test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(train_loader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 501, 64, 64])\n",
      "tensor([[   0],\n",
      "        [ 286],\n",
      "        [   0],\n",
      "        [   0],\n",
      "        [   0],\n",
      "        [ 951],\n",
      "        [ 951],\n",
      "        [ 389],\n",
      "        [   0],\n",
      "        [   0],\n",
      "        [ 951],\n",
      "        [1005],\n",
      "        [ 593],\n",
      "        [ 251],\n",
      "        [ 818],\n",
      "        [ 997],\n",
      "        [ 389],\n",
      "        [   0],\n",
      "        [1011],\n",
      "        [ 662],\n",
      "        [   0],\n",
      "        [  76],\n",
      "        [ 194],\n",
      "        [   0],\n",
      "        [   0],\n",
      "        [   0],\n",
      "        [ 210],\n",
      "        [   0],\n",
      "        [   0],\n",
      "        [   0],\n",
      "        [   0],\n",
      "        [   0]])\n",
      "1590\n"
     ]
    }
   ],
   "source": [
    "print(sample_batch[0].shape)\n",
    "print(sample_batch[1])\n",
    "print(len(train_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
