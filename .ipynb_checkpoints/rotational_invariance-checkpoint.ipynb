{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "# use widget in vscode\n",
    "\n",
    "plt.set_loglevel('critical')\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from importlib import reload # while updating code this is important\n",
    "import models \n",
    "from models import train_and_eval\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "user = 'abenneck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently I'm not using this\n",
    "def cutout(I,val=0.5):\n",
    "    rows = np.random.randint(0,I.shape[-2],(2,))    \n",
    "    rows.sort()\n",
    "    cols = np.random.randint(0,I.shape[-1],(2,))    \n",
    "    cols.sort()\n",
    "    I[...,rows[0]:rows[1],cols[0]:cols[1]] = val\n",
    "    return I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f3dbf-238b-460e-92b8-6ff53e196e3e",
   "metadata": {},
   "source": [
    "### Download data from the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d612a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if user == 'abenneck':\n",
    "    data_save_path = '/home/abenneck/rotnet_work/data'\n",
    "else: # user == 'dtward'\n",
    "    data_save_path = '/home/dtward/data'\n",
    "\n",
    "# Define transform using mean and std to normalize the input data\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "my_dataset = torchvision.datasets.CIFAR10(    \n",
    "    data_save_path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(),\n",
    "                                              torchvision.transforms.RandomCrop(32,padding=4,padding_mode='edge'),\n",
    "                                              torchvision.transforms.ToTensor(),                                              \n",
    "                                             # torchvision.transforms.Lambda(cutout)\n",
    "                                              normalize,\n",
    "                                             ]\n",
    "                                            )\n",
    ")\n",
    "\n",
    "# Define data loader for the CIFAR-10 data\n",
    "my_loader = DataLoader(my_dataset, batch_size=64, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e415e73f-fe86-4d9a-a1a8-aae41dba1864",
   "metadata": {},
   "source": [
    "### Download testing data from the CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_dataset_test = torchvision.datasets.CIFAR10(    \n",
    "#     data_save_path,\n",
    "#     train=False,\n",
    "#     download=True,\n",
    "#     transform=torchvision.transforms.Compose([\n",
    "#                                               torchvision.transforms.ToTensor(),\n",
    "#                                               normalize,\n",
    "#                                               ])\n",
    "# )\n",
    "# my_loader_test = DataLoader(my_dataset_test, batch_size=64, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = torchvision.transforms.Normalize(mean=0.5, std=0.5)\n",
    "# 0.5, 0.5 is used in medmnist code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e040fd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PIP: Preferred Installer Program; One of the main methods for installing Python packages\n",
    "# !pip install medmnist\n",
    "\n",
    "# from medmnist import DermaMNIST as Dataset\n",
    "from medmnist import BloodMNIST as Dataset\n",
    "#from medmnist import OrganAMNIST as Dataset\n",
    "#from medmnist import PathMNIST as Dataset\n",
    "#from medmnist import TissueMNIST as Dataset # really big\n",
    "#from medmnist import BreastMNIST as Dataset # much smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b393116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine normalization function + 0.5, 0.5 is used in medmnist code\n",
    "normalize = torchvision.transforms.Normalize(mean=0.5, std=0.5)\n",
    "\n",
    "my_dataset = Dataset(     \n",
    "    download=True,\n",
    "    split='train',    \n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),   \n",
    "                                              normalize\n",
    "                                             ]\n",
    "                                            )\n",
    ")\n",
    "\n",
    "# Intialize data loader for training data\n",
    "my_loader = DataLoader(my_dataset, batch_size=128, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset_val = Dataset(        \n",
    "    split='val',    \n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                              normalize,\n",
    "                                             ]\n",
    "                                            )\n",
    ")\n",
    "\n",
    "# Initialize data loader for validation data\n",
    "my_loader_val = DataLoader(my_dataset_val, batch_size=128, num_workers=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0223c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset_test = Dataset(        \n",
    "    split='test',    \n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                              normalize,\n",
    "                                             ]\n",
    "                                            )\n",
    ")\n",
    "\n",
    "# Intialize data loader for test data\n",
    "my_loader_test = DataLoader(my_dataset_test, batch_size=128, num_workers=8, shuffle=True)\n",
    "\n",
    "# Create set of all labels in the dataset\n",
    "labels = set()\n",
    "for x,l in my_loader_test:\n",
    "    labels_i = {li.squeeze().item() for li in l}\n",
    "    labels = labels.union(labels_i)\n",
    "n_labels = len(labels)    \n",
    "print(n_labels)\n",
    "\n",
    "# Define additional inputs to the model evaluation process\n",
    "device = 'cuda:0'\n",
    "nepochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cbf448-79f5-4226-a67a-668c89d59eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(net,my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path='', verbose = False):\n",
    "    \"\"\"Train and evaluate a deep learning model (net) using the provided train/test/val splits over 'nepochs'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : torch.nn.Module\n",
    "        A deep learning model defined using PyTorch's nn.Module class\n",
    "    my_loader : torch.utils.data.DataLoader\n",
    "        A DataLoader defined using PyTorch's torch.utils.data library which will help to manage the training data being input to the model\n",
    "    my_loader_val : torch.utils.data.DataLoader\n",
    "        A DataLoader defined using PyTorch's torch.utils.data library which will help to manage the validation data being input to the model\n",
    "    my_loader_test : torch.utils.data.DataLoader\n",
    "        A DataLoader defined using PyTorch's torch.utils.data library which will help to manage the testing data being input to the model\n",
    "    n0 : int\n",
    "        TODO: \n",
    "    device : str\n",
    "        The device on which torch computations will be performed\n",
    "    nepochs : int\n",
    "        The number of epochs to train the model\n",
    "    out_path : str\n",
    "        /the/location/fname.npz where the output dictionary of performance metrics will be saved\n",
    "    verbose : bool\n",
    "        (Default - False); If true, print out various parameters and performance metrics before and after training\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : dict\n",
    "        A dictionary containing various performance metrics computed during training, testing, and validation\n",
    "    \n",
    "    \"\"\"\n",
    "    # If verbose = True, print number of parameters in model\n",
    "    if verbose:\n",
    "        print(models.count_parameters(net))\n",
    "\n",
    "    # Train net using provided data loaders and return dict of performance metrics\n",
    "    out = train_and_eval(net,my_loader, my_loader_val, my_loader_test, device=device, nepochs=nepochs)\n",
    "    auc_val, auc_test, hard_auc_test, accuracy_test = out['auc_val'], out['auc_test'], out['hard_auc_test'], out['accuracy_test']\n",
    "    ind = auc_val.index(np.max(auc_val))\n",
    "\n",
    "    # if verbose = True, print key performance metrics\n",
    "    if verbose:\n",
    "        print('best auc, hard auc, accuracy')\n",
    "        print(auc_test[ind],hard_auc_test[ind], accuracy_test[ind])\n",
    "        print('final auc, hard auc, accuracy')\n",
    "        print(auc_test[-1],hard_auc_test[-1], accuracy_test[-1])\n",
    "\n",
    "    # Update several output values\n",
    "    out['n0'] = n0\n",
    "    out['n_parameters'] = models.count_parameters(net)\n",
    "    out['net'] = None\n",
    "\n",
    "    # Clear local memory\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # If out_path is provided, save outputs\n",
    "    if out_path != '':\n",
    "        np.savez(out_path, out)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e10d69",
   "metadata": {},
   "source": [
    "# 18 layer resnets from medmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aab476",
   "metadata": {},
   "source": [
    "## First the actual resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e877dfc-c8ce-41b4-b1d0-a1494fd2f00c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = models.ResNet18(n1=n_labels)\n",
    "n0 = 64\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/resnet18_out.npz'\n",
    "resnet18_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cee21d-a03f-40af-9923-90ddeb5fd648",
   "metadata": {},
   "source": [
    "### Load the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3d8b5-0c62-486a-9468-d3a63a3fcbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.load(out_path, allow_pickle = True)\n",
    "out = out['arr_0'].item()\n",
    "[k for k in out]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb14da34",
   "metadata": {},
   "source": [
    "## Next the rotnet with the same number of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfef577",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.RotNet18(n1=n_labels)\n",
    "n0 = 63\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/rotnet18_out.npz'\n",
    "rotnet18_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d9abd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is the \"default\" which does 63 layers (close to 64, but less)\n",
    "net = models.RotNet18(n1=n_labels,reflection=True)\n",
    "n0 = 63\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/refnet18_out.npz'\n",
    "refnet18_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cb7f23",
   "metadata": {},
   "source": [
    "## Next the rotnet with the same number of independent feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29844e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 18 layers was used in the medmnist\n",
    "# or let's try 32 scalars and 32 vectors (since they did 64 total), this would be 96 feature maps\n",
    "# this is way less parameters\n",
    "n0 = 96\n",
    "net = models.RotNet18(n0=n0,n1=n_labels)\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/rotnet18_n096_out.npz'\n",
    "rotnet18_n096_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above, but with reflection = True\n",
    "n0 = 96\n",
    "net = models.RotNet18(n0=n0,n1=n_labels,reflection=True)\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/refnet18_n096_out.npz'\n",
    "refnet18_n096_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aabd12e",
   "metadata": {},
   "source": [
    "## Last the rotnet with the same number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 layers was used in the medmnist\n",
    "# with 126 it does best, but its a bit more parameters than the resnet below\n",
    "# I could try 123, this is a tiny bit more but pretty close\n",
    "# I will do 120\n",
    "n0 = 120\n",
    "net = models.RotNet18(n0=n0,n1=n_labels) # (05/31/24): Original n0-126, changed to 120 based on comments and fname\n",
    "# 126 gives 11 million parameters, the resnet below is only 10 million, so we could do a bit less\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/rotnet18_n0120_out.npz'\n",
    "rotnet18_n0120_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44292831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 layers was used in the medmnist\n",
    "# for refnet I can use 159 parameters\n",
    "n0 = 159\n",
    "net = models.RotNet18(n0=n0,n1=n_labels,reflection=True)\n",
    "# 126 gives 11 million parameters, the resnet below is only 10 million, so we could do a bit less\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/refnet18_n0159_out.npz'\n",
    "refnet18_n0159_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e1ab2",
   "metadata": {},
   "source": [
    "# Now the 20 layer ones from cifar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7538546",
   "metadata": {},
   "source": [
    "## First the resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the resnet from the resnet paper for cifar10\n",
    "# it has 16 channels at its input layer, and about 267K parameters\n",
    "net = models.ResNet20(n1=n_labels)\n",
    "n0 = 16\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/resnet20_out.npz'\n",
    "resnet20_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ea23e",
   "metadata": {},
   "source": [
    "## Now the same number of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec749a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 layers is from cifar\n",
    "# default is 15 parameters, note this tends to be too little to do a good job\n",
    "n0 = 15\n",
    "net = models.RotNet20(n0=n0,n1=n_labels) # (05/31/24): Original script did not pass n0, so n0 was 16\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/rotnet20_out.npz'\n",
    "rotnet20_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf4bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 layers is from cifar\n",
    "# default is 15 parameters, note this tends to be too little to do a good job\n",
    "# try with reflection equivariance too, it's way fewer parameters\n",
    "n0 = 15\n",
    "net = models.RotNet20(n0=n0,n1=n_labels,reflection=True) # (05/31/24): Original script did not pass n0, so n0 was 16\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/refnet20_out.npz'\n",
    "refnet20_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b98e36",
   "metadata": {},
   "source": [
    "## Now the same number of independent feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdaa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 layers is from cifar\n",
    "# instead of matching parameters, match the number of scalar + vector components\n",
    "# the resnet20 uses 16 channels, so I'll do 8 scalar and 8 vector for 24 channels\n",
    "n0 = 24\n",
    "net = models.RotNet20(n0=n0,n1=n_labels)\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/rotnet20_n024_out.npz'\n",
    "rotnet20_n024_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e2141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 layers is from cifar\n",
    "# instead of matching parameters, match the number of scalar + vector components\n",
    "# the resnet20 uses 16 channels, so I'll do 8 scalar and 8 vector for 24 channels\n",
    "n0 = 24\n",
    "net = models.RotNet20(n0=n0,n1=n_labels,reflection=True)\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/refnet20_n024_out.npz'\n",
    "refnet20_n024_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04f4411",
   "metadata": {},
   "source": [
    "## Now the same number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8256a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 layers is from cifar\n",
    "# extra channels so it matches parameters\n",
    "# below is about we want less than 260K\n",
    "n0 = 30\n",
    "net = models.RotNet20(n0=n0,n1=n_labels)\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/rotnet20_n030_out.npz'\n",
    "rotnet20_n030_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 layers is from cifar\n",
    "# extra channels so it matches parameters\n",
    "# below is about we want less than 260K\n",
    "n0 = 39\n",
    "net = models.RotNet20(n0=n0,n1=n_labels,reflection=True)\n",
    "out_path = '/home/abenneck/rotnet_work/outputs/metrics/refnet20_n039_out.npz'\n",
    "refnet20_n039_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d36b0d",
   "metadata": {},
   "source": [
    "# plot the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be75c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[k for k in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eab53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['accuracy_train', 'accuracy_val','accuracy_test', \n",
    "        'auc_train', 'auc_val', 'auc_test',\n",
    "        'hard_auc_train', 'hard_auc_val', 'hard_auc_test']\n",
    "\n",
    "# rotnet18 defaults to 63 channels, so doing 66 is not very differet\n",
    "# rotnet20 had 15 channels efault\n",
    "outputs = [resnet18_out,rotnet18_out,rotnet18_n096_out,rotnet18_n0120_out,refnet18_out,refnet18_n096_out, refnet18_n0159_out, resnet20_out, rotnet20_out,rotnet20_n024_out,rotnet20_n030_out,refnet20_out,refnet20_n024_out,refnet20_n039_out]\n",
    "names = ['resnet18_64', 'rotnet18_63', 'rotnet18_96','rotnet18_120',      'refnet18_63','refnet18_96','refnet18_159',         'resnet20_16','rotnet20_15','rotnet20_24','rotnet20_30',       'refnet20_15','refnet20_24','refnet20_39']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation(names,outputs,measure):\n",
    "    \"\"\"Plot the outputs['measure'] for every model in 'names' for the highest metric during validation and the metric on the last iteration. 'Rotnet' models\n",
    "    \"\"\"\n",
    "\n",
    "    fig,ax = plt.subplots(1,2,sharey=True,sharex=True)\n",
    "    rot_angle = 60\n",
    "\n",
    "    k = '_'.join([measure,'test'])\n",
    "\n",
    "    colors = ['r' if 'rot' in n else ('m' if 'ref' in n else 'b') for n in names]\n",
    "\n",
    "    # this is the best\n",
    "    data = []\n",
    "    for out in outputs:\n",
    "        ind = np.argmax(out[k.replace('test','val')])\n",
    "        data.append(out[k][ind])\n",
    "    \n",
    "    ax[0].bar(names, data, color=colors)\n",
    "    ax[0].set_ylim(np.min(data)-0.01,np.max(data)+0.01)\n",
    "    for tick in ax[0].get_xticklabels():\n",
    "        tick.set_rotation(rot_angle)\n",
    "        tick.set_horizontalalignment('right')\n",
    "    ax[0].set_title(f'{measure.upper()}, best on validation')\n",
    "\n",
    "    # this is the last\n",
    "    data1 = [out[k][-1] for out in outputs]\n",
    "    ax[1].bar(names, data1, color=colors)\n",
    "    #ax[1].set_ylim(np.min(data1)-0.01,np.max(data1)+0.01)\n",
    "    ax[0].set_ylim(np.min(data+data1)-0.01,np.max(data+data1)+0.01)\n",
    "    for tick in ax[1].get_xticklabels():\n",
    "        tick.set_rotation(rot_angle)\n",
    "        tick.set_horizontalalignment('right')\n",
    "    ax[1].set_title(f'{measure.upper()}, last iteration')\n",
    "\n",
    "    # for axi in ax:\n",
    "    #     axi.set_ylim([0.6,1])\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.3)\n",
    "    fig.supxlabel('Model Name')\n",
    "    fig.supylabel('Performance Metric')\n",
    "\n",
    "    return fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac139c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "measures = ['accuracy','auc','hard_auc']\n",
    "for measure in measures:\n",
    "    fig,ax = plot_evaluation(names,outputs,measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b3f6b7",
   "metadata": {},
   "source": [
    "# comparing\n",
    "There are are a few ways we could compare models on \"equal footing\"\n",
    "\n",
    "1. We could use the same number of feature maps.\n",
    "1. We could use the same number of parameters\n",
    "1. We could count vector components as one feature and then use the same number of feature maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da87c02",
   "metadata": {},
   "source": [
    "# TODO\n",
    "make sure outputs are saved.  They should be named according to their architecture.  The dataset they are trained on.  And which repeat they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0306d662-d150-426e-b908-1a98a75d31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_models(Dataset, data_path, outdir, rep):\n",
    "    \n",
    "    # Redefine normalization function + 0.5, 0.5 is used in medmnist code\n",
    "    normalize = torchvision.transforms.Normalize(mean=0.5, std=0.5)\n",
    "    \n",
    "    # Intialize data loader for training data\n",
    "    my_dataset = Dataset(root=data_path, download=True, split='train', transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), normalize]))    \n",
    "    my_loader = DataLoader(my_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
    "\n",
    "    # Initialize data loader for validation data\n",
    "    my_dataset_val = Dataset(root=data_path, download=True, split='val', transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), normalize]))\n",
    "    my_loader_val = DataLoader(my_dataset_val, batch_size=128, num_workers=8, shuffle=True)\n",
    "\n",
    "    # Intialize data loader for test data\n",
    "    my_dataset_test = Dataset(root=data_path, download=True, split='test', transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),normalize]))\n",
    "    my_loader_test = DataLoader(my_dataset_test, batch_size=128, num_workers=8, shuffle=True)\n",
    "    \n",
    "    # Create set of all labels in for this dataset + count the total amount\n",
    "    labels = set()\n",
    "    for x,l in my_loader_test:\n",
    "        labels_i = {li.squeeze().item() for li in l}\n",
    "        labels = labels.union(labels_i)\n",
    "    n_labels = len(labels)    \n",
    "    \n",
    "    # Define additional inputs to the model evaluation process\n",
    "    device = 'cuda:0'\n",
    "    nepochs = 5\n",
    "\n",
    "    # Train and evaluate all models\n",
    "\n",
    "    outdir_metrics = os.path.join(outdir,'metrics')\n",
    "    if not os.path.exists(outdir_metrics):\n",
    "        os.mkdir(outdir_metrics)\n",
    "\n",
    "    start = time.time()\n",
    "    # =============================\n",
    "    # ===== 18 Layer Networks =====\n",
    "    # =============================\n",
    "    print('Starting 18 Layer Networks')\n",
    "    net = models.ResNet18(n1=n_labels)\n",
    "    n0 = 64\n",
    "    out_path = os.path.join(outdir_metrics, f'resnet18_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    resnet18_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    net = models.RotNet18(n1=n_labels)\n",
    "    n0 = 63\n",
    "    out_path = os.path.join(outdir_metrics, f'rotnet18_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    rotnet18_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    net = models.RotNet18(n1=n_labels,reflection=True)\n",
    "    n0 = 63\n",
    "    out_path = os.path.join(outdir_metrics, f'refnet18_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    refnet18_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 96\n",
    "    net = models.RotNet18(n0=n0,n1=n_labels)\n",
    "    out_path = os.path.join(outdir_metrics, f'rotnet18_n096_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    rotnet18_n096_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 96\n",
    "    net = models.RotNet18(n0=n0,n1=n_labels,reflection=True)\n",
    "    out_path = os.path.join(outdir_metrics, f'refnet18_n096_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    refnet18_n096_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 120\n",
    "    net = models.RotNet18(n0=n0,n1=n_labels)\n",
    "    out_path = os.path.join(outdir_metrics, f'rotnet18_n0120_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    rotnet18_n0120_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 159\n",
    "    net = models.RotNet18(n0=n0,n1=n_labels,reflection=True)\n",
    "    out_path = os.path.join(outdir_metrics, f'refnet18_n0159_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    refnet18_n0159_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    # =============================\n",
    "    # ===== 20 Layer Networks =====\n",
    "    # =============================\n",
    "    print('Starting 20 Layer Networks')\n",
    "    n0 = 16\n",
    "    net = models.ResNet20(n1=n_labels)\n",
    "    out_path = os.path.join(outdir_metrics, f'resnet20_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    resnet20_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 15\n",
    "    net = models.RotNet20(n0=n0,n1=n_labels)\n",
    "    out_path = os.path.join(outdir_metrics, f'rotnet20_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    rotnet20_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 15\n",
    "    net = models.RotNet20(n0=n0,n1=n_labels,reflection=True)\n",
    "    out_path = os.path.join(outdir_metrics, f'refnet20_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    refnet20_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 24\n",
    "    net = models.RotNet20(n0=n0,n1=n_labels)\n",
    "    out_path = os.path.join(outdir_metrics, f'rotnet20_n024_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    rotnet20_n024_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 24\n",
    "    net = models.RotNet20(n0=n0,n1=n_labels,reflection=True)\n",
    "    out_path = os.path.join(outdir_metrics, f'refnet20_n024_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    refnet20_n024_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 30\n",
    "    net = models.RotNet20(n0=n0,n1=n_labels)\n",
    "    out_path = os.path.join(outdir_metrics, f'rotnet20_n030_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    rotnet20_n030_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "\n",
    "    n0 = 39\n",
    "    net = models.RotNet20(n0=n0,n1=n_labels,reflection=True)\n",
    "    out_path = os.path.join(outdir_metrics, f'refnet20_n039_{Dataset.__name__}_r{rep}_out.npz')\n",
    "    refnet20_n039_out = test_model(net, my_loader, my_loader_val, my_loader_test, n0, device, nepochs, out_path)\n",
    "    print(f'Finished model training in {time.time() - start:.2f}s')\n",
    "\n",
    "    # ======================================\n",
    "    # ===== Compare model performances =====\n",
    "    # ======================================\n",
    "\n",
    "    # Define + create directory for output figures\n",
    "    outdir_fig = os.path.join(outdir,'figures')\n",
    "    if not os.path.exists(outdir_fig):\n",
    "        os.mkdir(outdir_fig)\n",
    "    \n",
    "    # Define lists to be used for evaluation\n",
    "    outputs = [resnet18_out, rotnet18_out, rotnet18_n096_out, rotnet18_n0120_out, refnet18_out, refnet18_n096_out, refnet18_n0159_out, resnet20_out, rotnet20_out, rotnet20_n024_out, rotnet20_n030_out, refnet20_out, refnet20_n024_out, refnet20_n039_out]\n",
    "    names =   ['resnet18_64', 'rotnet18_63', 'rotnet18_96', 'rotnet18_120',      'refnet18_63','refnet18_96',     'refnet18_159',     'resnet20_16','rotnet20_15','rotnet20_24',     'rotnet20_30',     'refnet20_15','refnet20_24',     'refnet20_39']\n",
    "    measures = ['accuracy','auc','hard_auc']\n",
    "    \n",
    "    for measure in measures:\n",
    "        fig,ax = plot_evaluation(names, outputs, measure)\n",
    "        if True:\n",
    "            fig.savefig(os.path.join(outdir_fig,f'{Dataset.__name__}_{measure}_performance.png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676a7d3-d4b9-405d-8229-7f88ccb27adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from medmnist import DermaMNIST as Dataset\n",
    "# from medmnist import BloodMNIST as Dataset\n",
    "from medmnist import OrganAMNIST as Dataset\n",
    "# from medmnist import PathMNIST as Dataset\n",
    "# from medmnist import TissueMNIST as Dataset # really big\n",
    "# from medmnist import BreastMNIST as Dataset # much smaller\n",
    "\n",
    "if user == 'abenneck':\n",
    "    data_save_path = '/home/abenneck/rotnet_work/data'\n",
    "else: # user == 'dtward'\n",
    "    data_save_path = '/home/dtward/data'\n",
    "\n",
    "outdir = '/home/abenneck/rotnet_work/outputs/'\n",
    "\n",
    "evaluate_all_models(Dataset, data_save_path, outdir, rep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930138cd-ebea-4135-8f75-37a0c794372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = data_save_path\n",
    "\n",
    "# Redefine normalization function + 0.5, 0.5 is used in medmnist code\n",
    "normalize = torchvision.transforms.Normalize(mean=0.5, std=0.5)\n",
    "\n",
    "# Intialize data loader for training data\n",
    "my_dataset = Dataset(root=data_path, download=True, split='train', transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), normalize]))    \n",
    "my_loader = DataLoader(my_dataset, batch_size=128, num_workers=8, shuffle=True)\n",
    "\n",
    "# Initialize data loader for validation data\n",
    "my_dataset_val = Dataset(root=data_path, download=True, split='val', transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(), normalize]))\n",
    "my_loader_val = DataLoader(my_dataset_val, batch_size=128, num_workers=8, shuffle=True)\n",
    "\n",
    "# Intialize data loader for test data\n",
    "my_dataset_test = Dataset(root=data_path, download=True, split='test', transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),normalize]))\n",
    "my_loader_test = DataLoader(my_dataset_test, batch_size=128, num_workers=8, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
